```PS C:\Users\Bharat Bhushan\Documents\k8project\Slab.ai\manifest> kubectl get nodes
NAME                          STATUS     ROLES           AGE   VERSION
cka-cluster01-control-plane   Ready      control-plane   20h   v1.31.2
cka-cluster01-worker          NotReady   <none>          20h   v1.31.2
cka-cluster01-worker2         NotReady   <none>          20h   v1.31.2
```
## How to start cka-cluster01-worker and cka-cluster01-worker2

## Solution:
The status `NotReady` for the `cka-cluster01-worker` and `cka-cluster01-worker2` nodes indicates that these nodes are not functioning properly or are not connected to the Kubernetes control plane. To get these nodes back to the `Ready` state, you'll need to investigate the issue and address it.
Here are the steps you can take to troubleshoot and resolve the issue:

### 1. **Check Node Logs**:
   First, check the logs for the `kubelet` on the worker nodes (`cka-cluster01-worker` and `cka-cluster01-worker2`). The `kubelet` is responsible for keeping the node registered with the Kubernetes control plane.

   - SSH into the worker node:
     ```bash
     ssh <worker-node-ip>
     ```
   
   - Check the status of `kubelet` service:
     ```bash
     systemctl status kubelet
     ```

   If the service is not running, try restarting it:
   ```bash
   sudo systemctl restart kubelet
   ```

   If there are any issues with `kubelet`, check the logs:
   ```bash
   journalctl -u kubelet -f
   ```

### 2. **Check Networking**:
   The worker nodes might be unreachable due to network issues, particularly if they cannot communicate with the control plane. Verify that the worker nodes can ping the control plane and vice versa.

   - Ping the control plane node from the worker node:
     ```bash
     ping <control-plane-ip>
     ```
   
   - Check firewall rules to ensure that ports required for Kubernetes communication are open (e.g., port 6443 for Kubernetes API server).

### 3. **Check the kubelet Configuration**:
   If the `kubelet` configuration is misconfigured (for example, wrong API server URL), the worker node may not be able to join the cluster.

   - Check `/etc/kubernetes/kubelet.conf` to ensure the correct API server URL and authentication credentials are in place.
   
### 4. **Check Node Registration**:
   If the `kubelet` is running but the node is still `NotReady`, it may not be able to register with the API server. Look for the error messages related to node registration in the kubelet logs.

### 5. **Check the Cloud Provider/VM Status**:
   If you're using cloud providers (e.g., AWS, GCP), ensure the VM instances for the worker nodes are running and accessible.

### 6. **Restart the Node or Cluster**:
   If the above steps don't resolve the issue, try restarting the affected worker node(s). You can do this via SSH to the node and running:
   ```bash
   sudo reboot
   ```

   Alternatively, if the issue persists, consider restarting the entire cluster or kubelet service on the master node as well:
   ```bash
   sudo systemctl restart kubelet
   ```

### 7. **Check the Kubernetes Control Plane**:
   Ensure the control plane (`cka-cluster01-control-plane`) is fully operational and there are no issues there:
   ```bash
   kubectl get componentstatuses
   ```

### 8. **Check the Node Status from Kubernetes**:
   You can also describe the nodes to see more details about why they are in the `NotReady` state:
   ```bash
   kubectl describe node cka-cluster01-worker
   kubectl describe node cka-cluster01-worker2
   ```

This will give you more information on the conditions leading to their `NotReady` state.

---

### Summary of steps:
1. **Check `kubelet` service on worker nodes**.
2. **Verify networking and connectivity** between nodes and control plane.
3. **Check kubelet configuration** on worker nodes.
4. **Reboot the nodes** or **restart services** if necessary.
5. **Verify cloud provider or VM status** if applicable.
6. **Check Kubernetes control plane health**.

After these steps, the worker nodes should become `Ready`. If the issue persists, let me know the specific error messages from the logs for further troubleshooting.
