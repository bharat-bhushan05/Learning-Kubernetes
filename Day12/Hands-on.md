A **hands-on lab** to simulate and troubleshoot common **DaemonSet issues** in a Kubernetes cluster. This will help you understand real-world scenarios and how to fix them effectively.  

---

# **ğŸ”¥ DaemonSet Troubleshooting Hands-on Lab**
### **ğŸ› ï¸ Lab Setup**
We will:
âœ… Create a **DaemonSet**  
âœ… Simulate **various issues**  
âœ… Debug and troubleshoot  

---

## **ğŸ“ Step 1: Create a Kubernetes Cluster**
If you don't already have a cluster, start **Minikube** or use any existing cluster.  
```bash
minikube start
```
Or use **kind (Kubernetes in Docker)**:  
```bash
kind create cluster --name daemonset-lab
```

---

## **ğŸ“ Step 2: Create a DaemonSet**
Save this YAML as `fluentd-daemonset.yaml`:  
```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      containers:
      - name: fluentd
        image: fluentd:latest
        resources:
          limits:
            memory: "256Mi"
            cpu: "100m"
          requests:
            memory: "128Mi"
            cpu: "50m"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
```
Apply the DaemonSet:
```bash
kubectl apply -f fluentd-daemonset.yaml
```

Check if the DaemonSet is running:  
```bash
kubectl get daemonsets -n kube-system
kubectl get pods -o wide -n kube-system
```

---

# **ğŸ› ï¸ Step 3: Simulate & Troubleshoot Common Issues**
Now, weâ€™ll simulate **real-world errors** and debug them.

---

## **ğŸ”¥ Scenario 1: DaemonSet Pods Not Scheduled on Nodes**
### **âŒ Problem: DaemonSet pods are pending**
Check if any pod is stuck in `Pending`:
```bash
kubectl get pods -n kube-system -o wide
```
If the output shows `STATUS: Pending`, find out why:
```bash
kubectl describe pod <pod-name> -n kube-system
```
### **ğŸ” Fix:**
1ï¸âƒ£ Check if nodes are labeled correctly:
```bash
kubectl get nodes --show-labels
```
If missing, add the required label:
```bash
kubectl label node <node-name> app=fluentd
```
2ï¸âƒ£ Check **taints**:
```bash
kubectl describe node <node-name> | grep -i taint
```
If the node is **tainted**, add a toleration in the DaemonSet YAML.

---

## **ğŸ”¥ Scenario 2: Pods in CrashLoopBackOff**
### **âŒ Problem: Fluentd pods keep restarting**
```bash
kubectl get pods -n kube-system
```
If pods are in `CrashLoopBackOff`, check logs:
```bash
kubectl logs -n kube-system <pod-name>
```
### **ğŸ” Fix:**
1ï¸âƒ£ If memory is insufficient:
```yaml
resources:
  limits:
    memory: "512Mi"
    cpu: "200m"
  requests:
    memory: "256Mi"
    cpu: "100m"
```
Apply changes:
```bash
kubectl apply -f fluentd-daemonset.yaml
```

2ï¸âƒ£ If the container crashes due to missing config:
```bash
kubectl describe pod <pod-name> -n kube-system
```
Fix any incorrect environment variables or mounts.

---

## **ğŸ”¥ Scenario 3: ImagePullBackOff**
### **âŒ Problem: Incorrect container image**
Check the pod status:
```bash
kubectl get pods -n kube-system
```
If the `STATUS` is `ImagePullBackOff`:
```bash
kubectl describe pod <pod-name> -n kube-system
```
### **ğŸ” Fix:**
1ï¸âƒ£ Update the **correct image version**:
```yaml
containers:
- name: fluentd
  image: fluentd:v1.14
```
Apply the fix:
```bash
kubectl apply -f fluentd-daemonset.yaml
```
2ï¸âƒ£ If using a **private registry**, add a secret:
```yaml
imagePullSecrets:
- name: my-registry-secret
```

---

## **ğŸ”¥ Scenario 4: Some Nodes Do Not Have DaemonSet Pods**
### **âŒ Problem: Pods missing on specific nodes**
Check on which nodes DaemonSet pods are running:
```bash
kubectl get pods -o wide -n kube-system
```
If a node is missing a pod:
```bash
kubectl describe node <node-name>
```
### **ğŸ” Fix:**
1ï¸âƒ£ If nodes are missing required labels, add them:
```bash
kubectl label node <node-name> role=worker
```
2ï¸âƒ£ If a node is **tainted**, add toleration:
```yaml
tolerations:
- key: "node-role.kubernetes.io/master"
  operator: "Exists"
  effect: "NoSchedule"
```

---

## **ğŸ”¥ Scenario 5: DaemonSet Not Updating**
### **âŒ Problem: Pods do not update after applying changes**
If you updated the DaemonSet but pods still run the old version:
```bash
kubectl rollout status daemonset fluentd -n kube-system
```
### **ğŸ” Fix:**
1ï¸âƒ£ **Use RollingUpdate strategy instead of OnDelete**:
```yaml
updateStrategy:
  type: RollingUpdate
```
Apply changes:
```bash
kubectl apply -f fluentd-daemonset.yaml
```
2ï¸âƒ£ **Manually delete old pods**:
```bash
kubectl delete pod --selector=name=fluentd -n kube-system
```

---

## **ğŸ”¥ Scenario 6: Debugging Logs & Events**
Check DaemonSet **events**:
```bash
kubectl get events -n kube-system | grep fluentd
```
Check **detailed pod logs**:
```bash
kubectl logs -f daemonset/fluentd -n kube-system
```

---

# **ğŸ¯ Conclusion**
ğŸš€ You have successfully simulated and **troubleshooted** various **DaemonSet issues** in Kubernetes!  
This hands-on lab prepares you for **real-world debugging** and **Kubernetes interviews**. ğŸ”¥  
